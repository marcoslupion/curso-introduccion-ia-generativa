{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90490b25",
   "metadata": {},
   "source": [
    "# Fine-tuning de S-BERT con Aprendizaje Contrastivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e6a8c",
   "metadata": {},
   "source": [
    "Asumimos que S-BERT se ha entrenado en un contexto similar al contexto actual.\n",
    "\n",
    "Se usa un aprendizaje contrastivo para afinar S-BERT con nuestro dataset nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos las librerías necesarias si no están ya instaladas\n",
    "!pip install sentence-transformers transformers torch datasets -q "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa85c92",
   "metadata": {},
   "source": [
    "## Fine-tuning de un S-BERT pre-entrenado utilizando Aprendizaje Contrastivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5929d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "014dae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcos\\Programas\\Python3.8\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.901, 'train_samples_per_second': 1.052, 'train_steps_per_second': 0.526, 'train_loss': 0.2283397763967514, 'epoch': 1.0}\n",
      "Fine-tuning del modelo S-BERT con aprendizaje contrastivo completado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses, InputExample, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Cargar un modelo S-BERT pre-entrenado\n",
    "sbert_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Crear ejemplos para el aprendizaje contrastivo (positivos y negativos)\n",
    "train_examples = [\n",
    "    InputExample(texts=['Frase similar A', 'Frase similar B'], label=0.8),\n",
    "    InputExample(texts=['Frase no relacionada A', 'Frase no relacionada B'], label=0.2),\n",
    "]\n",
    "\n",
    "# Crear un DataLoader para el entrenamiento con aprendizaje contrastivo\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=8)\n",
    "\n",
    "# Definir la pérdida para el aprendizaje contrastivo\n",
    "train_loss = losses.CosineSimilarityLoss(model=sbert_model)\n",
    "\n",
    "# Entrenar el modelo utilizando el aprendizaje contrastivo\n",
    "sbert_model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100)\n",
    "print(\"Fine-tuning del modelo S-BERT con aprendizaje contrastivo completado.\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
