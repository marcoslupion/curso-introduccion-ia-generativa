{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5afcb4",
   "metadata": {},
   "source": [
    "# Recomendaciones de Películas con Word2Vec\n",
    "En este notebook, vamos a utilizar un dataset de recomendaciones de películas para entrenar un modelo **Word2Vec**. Este modelo nos permitirá encontrar películas similares a partir de las listas de películas que los usuarios han visto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "177b6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from transformers import AutoTokenizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f5bb0",
   "metadata": {},
   "source": [
    "## Carga del Dataset\n",
    "Vamos a utilizar el dataset de **MovieLens**, que contiene información sobre las películas vistas por los usuarios. Descargaremos los datos y los prepararemos para el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772c74f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas de las películas:\n",
      "   movieId                               title   \n",
      "0        1                    Toy Story (1995)  \\\n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "Primeras filas de las calificaciones:\n",
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n"
     ]
    }
   ],
   "source": [
    "# Descargar el dataset de MovieLens\n",
    "movies_data = pd.read_csv('archivos/CursoGenAI_UAL_02_embeddingsWord2Vec_movies.csv')\n",
    "ratings_data = pd.read_csv('archivos/CursoGenAI_UAL_02_embeddingsWord2Vec_ratings.csv')\n",
    "\n",
    "# Mostrar las primeras filas del dataset de películas y ratings para asegurarnos de que la carga fue exitosa\n",
    "print(\"Primeras filas de las películas:\")\n",
    "print(movies_data.head())\n",
    "\n",
    "print(\"Primeras filas de las calificaciones:\")\n",
    "print(ratings_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe4e76",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Datos\n",
    "Ahora, vamos a preparar el dataset para el entrenamiento del modelo Word2Vec. Vamos a agrupar las películas vistas por cada usuario para formar secuencias que representen las listas de reproducción de cada usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83701270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras secuencias de películas vistas por usuarios:\n",
      "[[1, 3, 6, 47, 50, 70, 101, 110, 151, 157, 163, 216, 223, 231, 235, 260, 296, 316, 333, 349, 356, 362, 367, 423, 441, 457, 480, 500, 527, 543, 552, 553, 590, 592, 593, 596, 608, 648, 661, 673, 733, 736, 780, 804, 919, 923, 940, 943, 954, 1009, 1023, 1024, 1025, 1029, 1030, 1031, 1032, 1042, 1049, 1060, 1073, 1080, 1089, 1090, 1092, 1097, 1127, 1136, 1196, 1197, 1198, 1206, 1208, 1210, 1213, 1214, 1219, 1220, 1222, 1224, 1226, 1240, 1256, 1258, 1265, 1270, 1275, 1278, 1282, 1291, 1298, 1348, 1377, 1396, 1408, 1445, 1473, 1500, 1517, 1552, 1573, 1580, 1587, 1617, 1620, 1625, 1644, 1676, 1732, 1777, 1793, 1804, 1805, 1920, 1927, 1954, 1967, 2000, 2005, 2012, 2018, 2028, 2033, 2046, 2048, 2054, 2058, 2078, 2090, 2093, 2094, 2096, 2099, 2105, 2115, 2116, 2137, 2139, 2141, 2143, 2161, 2174, 2193, 2253, 2268, 2273, 2291, 2329, 2338, 2353, 2366, 2387, 2389, 2395, 2406, 2414, 2427, 2450, 2459, 2470, 2478, 2492, 2502, 2528, 2529, 2542, 2571, 2580, 2596, 2616, 2617, 2628, 2640, 2641, 2644, 2648, 2654, 2657, 2692, 2700, 2716, 2761, 2797, 2826, 2858, 2872, 2899, 2916, 2944, 2947, 2948, 2949, 2959, 2985, 2987, 2991, 2993, 2997, 3033, 3034, 3052, 3053, 3062, 3147, 3168, 3176, 3243, 3247, 3253, 3273, 3386, 3439, 3440, 3441, 3448, 3450, 3479, 3489, 3527, 3578, 3617, 3639, 3671, 3702, 3703, 3729, 3740, 3744, 3793, 3809, 4006, 5060], [318, 333, 1704, 3578, 6874, 8798, 46970, 48516, 58559, 60756, 68157, 71535, 74458, 77455, 79132, 80489, 80906, 86345, 89774, 91529, 91658, 99114, 106782, 109487, 112552, 114060, 115713, 122882, 131724], [31, 527, 647, 688, 720, 849, 914, 1093, 1124, 1263, 1272, 1275, 1302, 1371, 1587, 2018, 2080, 2090, 2105, 2288, 2424, 2851, 3024, 3210, 3703, 3949, 4518, 5048, 5181, 5746, 5764, 5919, 6238, 6835, 7899, 7991, 26409, 70946, 72378], [21, 32, 45, 47, 52, 58, 106, 125, 126, 162, 171, 176, 190, 215, 222, 232, 235, 247, 260, 265, 296, 319, 342, 345, 348, 351, 357, 368, 417, 441, 450, 457, 475, 492, 509, 538, 539, 553, 588, 593, 595, 599, 608, 648, 708, 759, 800, 892, 898, 899, 902, 904, 908, 910, 912, 914, 919, 920, 930, 937, 1025, 1046, 1057, 1060, 1073, 1077, 1079, 1080, 1084, 1086, 1094, 1103, 1136, 1179, 1183, 1188, 1196, 1197, 1198, 1199, 1203, 1211, 1213, 1219, 1225, 1250, 1259, 1265, 1266, 1279, 1282, 1283, 1288, 1291, 1304, 1391, 1449, 1466, 1500, 1517, 1580, 1597, 1617, 1641, 1704, 1719, 1732, 1733, 1734, 1834, 1860, 1883, 1885, 1892, 1895, 1907, 1914, 1916, 1923, 1947, 1966, 1967, 1968, 2019, 2076, 2078, 2109, 2145, 2150, 2174, 2186, 2203, 2204, 2282, 2324, 2336, 2351, 2359, 2390, 2395, 2406, 2467, 2571, 2583, 2599, 2628, 2683, 2692, 2712, 2762, 2763, 2770, 2791, 2843, 2858, 2874, 2921, 2926, 2959, 2973, 2997, 3033, 3044, 3060, 3079, 3083, 3160, 3175, 3176, 3204, 3255, 3317, 3358, 3365, 3386, 3408, 3481, 3489, 3508, 3538, 3591, 3788, 3809, 3851, 3897, 3911, 3967, 3996, 4002, 4014, 4020, 4021, 4027, 4029, 4033, 4034, 4074, 4121, 4144, 4166, 4226, 4239, 4246, 4252, 4260, 4273, 4308, 4347, 4381, 4641, 4741, 4765, 4881, 4896, 4902, 4967], [1, 21, 34, 36, 39, 50, 58, 110, 150, 153, 232, 247, 253, 261, 265, 266, 290, 296, 300, 316, 318, 344, 349, 357, 364, 367, 380, 410, 457, 474, 475, 515, 527, 531, 534, 588, 589, 590, 592, 594, 595, 596, 597, 608]]\n"
     ]
    }
   ],
   "source": [
    "# Agrupar las películas vistas por cada usuario\n",
    "user_movie_sequences = ratings_data.groupby('userId')['movieId'].apply(list).tolist()\n",
    "\n",
    "# Filtrar listas que contengan más de una película\n",
    "filtered_sequences = [sequence for sequence in user_movie_sequences if len(sequence) > 1]\n",
    "\n",
    "# Mostrar algunas secuencias de películas\n",
    "print(\"Primeras secuencias de películas vistas por usuarios:\")\n",
    "print(filtered_sequences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a95c5d3",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo Word2Vec\n",
    "Usaremos las secuencias de películas vistas por los usuarios para entrenar el modelo Word2Vec, lo que nos permitirá identificar relaciones entre películas según cómo se ven juntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05096b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo Word2Vec con las secuencias de películas\n",
    "embedding_model = Word2Vec(\n",
    "    filtered_sequences, vector_size=32, window=5, negative=15, min_count=1, workers=4\n",
    ")\n",
    "\n",
    "# Guardar el modelo entrenado para su uso posterior\n",
    "embedding_model.save(\"movie_recommendation_word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78f725",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo\n",
    "Ahora que el modelo está entrenado, vamos a probarlo encontrando las películas más similares a una película dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf367bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Películas similares a la película con ID 1 (Toy Story):\n",
      "Título: Twelve Monkeys (a.k.a. 12 Monkeys) (1995) - Similaridad: 0.9950618743896484\n",
      "Título: Ace Ventura: When Nature Calls (1995) - Similaridad: 0.9945407509803772\n",
      "Título: Babe (1995) - Similaridad: 0.9940406680107117\n",
      "Título: GoldenEye (1995) - Similaridad: 0.9934611916542053\n",
      "Título: Sense and Sensibility (1995) - Similaridad: 0.9923250675201416\n",
      "Título: Leaving Las Vegas (1995) - Similaridad: 0.9913697838783264\n",
      "Título: Heat (1995) - Similaridad: 0.9897852540016174\n",
      "Título: Jumanji (1995) - Similaridad: 0.9893587827682495\n",
      "Título: Casino (1995) - Similaridad: 0.9862034916877747\n",
      "Título: Sabrina (1995) - Similaridad: 0.9851760268211365\n"
     ]
    }
   ],
   "source": [
    "# Definir una película específica por su ID\n",
    "target_movie_id = 1  # Por ejemplo, ID de la película \"Toy Story (1995)\"\n",
    "\n",
    "# Obtener las películas más similares a la película especificada\n",
    "similar_movies = embedding_model.wv.most_similar(positive=[target_movie_id])\n",
    "print(\"Películas similares a la película con ID 1 (Toy Story):\")\n",
    "for movie_id, similarity in similar_movies:\n",
    "    movie_title = movies_data.loc[movies_data['movieId'] == movie_id, 'title'].values[0]\n",
    "    print(f\"Título: {movie_title} - Similaridad: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03094ce7",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "\n",
    "Esta es la documentación de word2vec: https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e34f04",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f1cd8",
   "metadata": {},
   "source": [
    "¿Qué vector de embedding tienen las siguientes películas?\n",
    "- Paper, The (1994)\n",
    "- Ruby in Paradise (1993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dcba022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Películas similares a la película con ID 371:\n",
      "Título: Naked Gun 33 1/3: The Final Insult (1994) - Similaridad: 0.996755063533783\n",
      "Título: Timecop (1994) - Similaridad: 0.9963018298149109\n",
      "Título: Richie Rich (1994) - Similaridad: 0.996067225933075\n",
      "Título: It Could Happen to You (1994) - Similaridad: 0.9958513379096985\n",
      "Título: Red Rock West (1992) - Similaridad: 0.995254635810852\n",
      "Título: Flintstones, The (1994) - Similaridad: 0.9937567114830017\n",
      "Título: Wes Craven's New Nightmare (Nightmare on Elm Street Part 7: Freddy's Finale, A) (1994) - Similaridad: 0.9929433465003967\n",
      "Título: Carlito's Way (1993) - Similaridad: 0.9922701716423035\n",
      "Título: Beverly Hills Cop III (1994) - Similaridad: 0.9921116232872009\n",
      "Título: Speed (1994) - Similaridad: 0.9918348789215088\n",
      "Embedding: \n",
      "(32,)\n",
      "Películas similares a la película con ID 523:\n",
      "Título: Shadow, The (1994) - Similaridad: 0.9944896697998047\n",
      "Título: Sirens (1994) - Similaridad: 0.9939926266670227\n",
      "Título: Secret Garden, The (1993) - Similaridad: 0.993453860282898\n",
      "Título: Cowboy Way, The (1994) - Similaridad: 0.9929799437522888\n",
      "Título: Shadowlands (1993) - Similaridad: 0.9927369356155396\n",
      "Título: Romper Stomper (1992) - Similaridad: 0.9925701022148132\n",
      "Título: Serial Mom (1994) - Similaridad: 0.9925602674484253\n",
      "Título: Even Cowgirls Get the Blues (1993) - Similaridad: 0.9925446510314941\n",
      "Título: Spanking the Monkey (1994) - Similaridad: 0.9921889901161194\n",
      "Título: Short Cuts (1993) - Similaridad: 0.992082953453064\n"
     ]
    }
   ],
   "source": [
    "# En el archivo de películas, buscamos el ID de las películas:\n",
    "target_movie_id = 371\n",
    "similar_movies = embedding_model.wv.most_similar(positive=[target_movie_id])\n",
    "print(f\"Películas similares a la película con ID {target_movie_id}:\")\n",
    "for movie_id, similarity in similar_movies:\n",
    "    movie_title = movies_data.loc[movies_data['movieId'] == movie_id, 'title'].values[0]\n",
    "    print(f\"Título: {movie_title} - Similaridad: {similarity}\")\n",
    "print(\"Embedding: \")\n",
    "print(embedding_model.wv[target_movie_id].shape)\n",
    "\n",
    "\n",
    "target_movie_id = 523\n",
    "similar_movies = embedding_model.wv.most_similar(positive=[target_movie_id])\n",
    "print(f\"Películas similares a la película con ID {target_movie_id}:\")\n",
    "for movie_id, similarity in similar_movies:\n",
    "    movie_title = movies_data.loc[movies_data['movieId'] == movie_id, 'title'].values[0]\n",
    "    print(f\"Título: {movie_title} - Similaridad: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2be0f4",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "¿Cómo podría entrenar Word2Vec con el archivo del quijote?\n",
    "Impleméntalo y obtén las palabras más similares a:\n",
    "- Quijote\n",
    "- Sancho\n",
    "- Panza\n",
    "- Molino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63740fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcos\\Programas\\Python3.8\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto se ha dividido en 2098 fragmentos.\n",
      "Ejemplo de fragmento tokenizado: ['el', 'ing', '##eni', '##oso', 'hidalgo', 'don', 'qui', '##jo', '##te', 'de']\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Leer el archivo .txt\n",
    "with open('archivos/quijote.txt', 'r', encoding='utf-8') as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "# Inicializar el tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Paso 2: Dividir el texto en bloques más pequeños de 1000 caracteres\n",
    "max_length = 1000  # Ajustar según tus necesidades\n",
    "text_chunks = [text_content[i:i + max_length] for i in range(0, len(text_content), max_length)]\n",
    "\n",
    "# Paso 3: Tokenizar cada fragmento de texto\n",
    "token_chunks = [tokenizer.tokenize(chunk) for chunk in text_chunks]\n",
    "\n",
    "# Verificar la cantidad de fragmentos y algunos ejemplos para asegurar que la tokenización es correcta\n",
    "print(f\"El texto se ha dividido en {len(token_chunks)} fragmentos.\")\n",
    "print(\"Ejemplo de fragmento tokenizado:\", token_chunks[0][:10])  # Mostrar los primeros 10 tokens del primer fragmento\n",
    "\n",
    "# Paso 4: Entrenar el modelo Word2Vec utilizando las listas de tokens\n",
    "embedding_model = Word2Vec(\n",
    "    token_chunks, vector_size=32, window=3, negative=15, min_count=1, workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d19aacbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quijote\t[('fernando', 0.7667080760002136), ('antonio', 0.7060130834579468), ('luis', 0.6953632235527039), ('pedro', 0.6646602749824524), ('diego', 0.6328753232955933), ('-', 0.6298264265060425), ('lorenzo', 0.6247361302375793), ('juan', 0.6104427576065063), ('##de', 0.5775159597396851), ('alvaro', 0.5738563537597656)]\n",
      "Sancho\t[('teresa', 0.7062196731567383), ('-', 0.6502576470375061), ('di', 0.6499964594841003), (':', 0.6021126508712769), ('pan', 0.5912923812866211), ('rep', 0.568871259689331), ('##lic', 0.5557653903961182), ('##jo', 0.5527087450027466), ('barber', 0.5388609170913696), ('ya', 0.5344620943069458)]\n",
      "Panza\t[('teresa', 0.7032684087753296), ('lan', 0.619231641292572), ('belle', 0.5934838652610779), ('grande', 0.5648461580276489), ('##ste', 0.5349306464195251), ('noble', 0.5310447812080383), ('gibraltar', 0.5260404348373413), ('##dan', 0.5075939297676086), ('rus', 0.4996979832649231), ('##gr', 0.49007904529571533)]\n",
      "Molino\t[('lan', 0.7117639780044556), ('fine', 0.7056227326393127), ('roll', 0.6870951652526855), ('candi', 0.6845898032188416), ('cape', 0.6762033700942993), ('punta', 0.6606603860855103), ('crude', 0.6553086042404175), ('##jic', 0.6503872871398926), ('##iz', 0.6497904658317566), ('##rod', 0.6418290138244629)]\n"
     ]
    }
   ],
   "source": [
    "array_palabras = [\"Quijote\",\"Sancho\",\"Panza\",\"Molino\"]\n",
    "for palabra in array_palabras:\n",
    "    palabra_codificada = tokenizer.tokenize(palabra)\n",
    "    print(f'{palabra}\\t{embedding_model.wv.most_similar(positive=palabra_codificada)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcc6abc",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "En este notebook, utilizamos un modelo Word2Vec para analizar las relaciones entre películas basadas en las preferencias de los usuarios. Este enfoque puede ayudar a mejorar los sistemas de recomendación de películas, sugiriendo títulos que son más relevantes para los intereses del usuario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
