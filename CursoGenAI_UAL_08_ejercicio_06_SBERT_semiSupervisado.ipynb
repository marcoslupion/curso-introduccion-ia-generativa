{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab14e27",
   "metadata": {},
   "source": [
    "# Anotación Automática y Entrenamiento de S-BERT usando Contrastive Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4579f418",
   "metadata": {},
   "source": [
    "\n",
    "En este notebook, abordaremos el problema de la falta de datasets completamente anotados mediante un enfoque basado en aprendizaje contrastivo y anotación automática.\n",
    "\n",
    "### Objetivos:\n",
    "1. Utilizar un **Golden Dataset** pequeño para entrenar un modelo BERT como cross-encoder.\n",
    "2. Emplear **aprendizaje contrastivo** para entrenar el cross-encoder, donde la salida indica la similitud entre dos frases.\n",
    "3. Utilizar el BERT preentrenado para **anotar automáticamente** el resto del dataset.\n",
    "4. Entrenar un modelo **S-BERT** usando aprendizaje contrastivo para mejorar la calidad de las anotaciones y obtener embeddings más precisos.\n",
    "\n",
    "Este proceso tiene como objetivo reducir la necesidad de anotaciones manuales y mejorar la calidad del etiquetado del dataset utilizando técnicas avanzadas de NLP.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82e3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos las librerías necesarias si no están ya instaladas\n",
    "!pip install transformers sentence-transformers torch datasets -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50039563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7538e3",
   "metadata": {},
   "source": [
    "## Entrenar BERT como cross-encoder usando un Golden Dataset pequeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e307bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize pairs of questions\n",
    "def tokenize_pairs(example):\n",
    "    # Tokenize the question pairs using the tokenizer with padding and truncation\n",
    "    tokenized_output = tokenizer(\n",
    "        example[\"sentence1\"],\n",
    "        example[\"sentence2\"],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256  \n",
    "    )\n",
    "    # Add the label to the tokenized output and convert it to float type\n",
    "    tokenized_output[\"labels\"] = [float(label) for label in example[\"label\"]]\n",
    "    tokenized_output[\"sentence1\"] = example[\"sentence1\"]\n",
    "    tokenized_output[\"sentence2\"] = example[\"sentence2\"]\n",
    "    tokenized_output[\"similarity_score\"] = tokenized_output[\"labels\"]\n",
    "    return tokenized_output\n",
    "\n",
    "\n",
    "\n",
    "golden_dataset = load_dataset(\"sentence-transformers/quora-duplicates\", \"pair-class\", split=\"train[1%:2%]\")\n",
    "golden_dataset = golden_dataset.map(tokenize_pairs, batched=True)\n",
    "\n",
    "test_dataset = load_dataset(\"sentence-transformers/quora-duplicates\", \"pair-class\", split=\"train[2%:3%]\")\n",
    "test_dataset = test_dataset.map(tokenize_pairs, batched=True)\n",
    "\n",
    "big_train_dataset = load_dataset(\"sentence-transformers/quora-duplicates\", \"pair-class\", split=\"train[3%:6%]\")\n",
    "big_train_dataset = big_train_dataset.map(tokenize_pairs, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dcdd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "\n",
    "# Configure the training arguments for the Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    warmup_steps=100,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    report_to='none'  # Evitar reportes innecesarios si solo estamos probando  \n",
    ")\n",
    "\n",
    "# Initialize the Trainer with the model, arguments, and dataset\n",
    "trainer_golden = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=golden_dataset,\n",
    "    eval_dataset = test_dataset\n",
    ")\n",
    "\n",
    "# Train the model using contrastive learning\n",
    "trainer_golden.train()\n",
    "print(\"Training of the cross-encoder BERT completed using the Golden Dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fc59e",
   "metadata": {},
   "source": [
    "## Anotación automática del dataset utilizando BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Function to annotate the dataset using the trained BERT model\n",
    "def predict_similarity(example):\n",
    "    # Tokenize the question pairs\n",
    "    inputs = tokenizer(\n",
    "        example[\"sentence1\"],\n",
    "        example[\"sentence2\"],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'  # Return PyTorch tensors instead of lists\n",
    "    )\n",
    "\n",
    "    # Move inputs to the appropriate device (if you are using a GPU)\n",
    "    #inputs = {key: value for key, value in inputs.items()}\n",
    "\n",
    "    # Perform prediction with no gradient calculation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        similarity_score = torch.sigmoid(outputs.logits).item()\n",
    "    inputs[\"similarity_score\"] = similarity_score\n",
    "    inputs[\"sentence1\"] = example[\"sentence1\"]\n",
    "    inputs[\"sentence2\"] = example[\"sentence2\"]\n",
    "    print(inputs[\"similarity_score\"])\n",
    "    return inputs\n",
    "\n",
    "# Annotate the rest of the dataset\n",
    "big_train_dataset = big_train_dataset.map(predict_similarity)\n",
    "print(\"Anotación automática del dataset utilizando BERT completada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be54129",
   "metadata": {},
   "source": [
    "## Entrenar S-BERT usando aprendizaje contrastivo con el dataset anotado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5306b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "big_train_dataset_samples = [InputExample(texts=[row['sentence1'], row['sentence2']], label=row['similarity_score']) for row in big_train_dataset]\n",
    "golden_train_dataset_samples = [InputExample(texts=[row['sentence1'], row['sentence2']], label=row['similarity_score']) for row in golden_dataset]\n",
    "test_dataset_samples = [InputExample(texts=[row['sentence1'], row['sentence2']], label=row['similarity_score']) for row in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ccf525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar un modelo S-BERT pre-entrenado\n",
    "sbert_model_golden = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Crear un DataLoader para el entrenamiento con aprendizaje contrastivo\n",
    "train_dataloader_golden = DataLoader(golden_train_dataset_samples, shuffle=True, batch_size=8)\n",
    "\n",
    "# Definir la pérdida para el aprendizaje contrastivo\n",
    "train_loss = losses.CosineSimilarityLoss(model=sbert_model_golden)\n",
    "\n",
    "# Entrenar el modelo S-BERT utilizando el aprendizaje contrastivo\n",
    "sbert_model_golden.fit(train_objectives=[(train_dataloader_golden, train_loss)], epochs=1, warmup_steps=100)\n",
    "print(\"Entrenamiento del S-BERT con aprendizaje contrastivo completado usando el dataset anotado automáticamente.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "\n",
    "# Initialize the evaluator\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=test_dataset[\"sentence1\"],\n",
    "    sentences2=test_dataset[\"sentence2\"],\n",
    "    scores=test_dataset[\"similarity_score\"],\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    name=\"sts-dev\",\n",
    ")\n",
    "# You can run evaluation like so:\n",
    "dev_evaluator(sbert_model_golden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd973a5",
   "metadata": {},
   "source": [
    "# Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3aaed5",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "Comparar el entrenamiento de S-BERT con los diferentes datasets (excepto el test). ¿Con cual ofrece mejores resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd3ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Cargar un modelo S-BERT pre-entrenado\n",
    "sbert_model_fullTain = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Crear un DataLoader para el entrenamiento con aprendizaje contrastivo\n",
    "train_dataloader_full = DataLoader(big_train_dataset_samples, shuffle=True, batch_size=8)\n",
    "\n",
    "# Definir la pérdida para el aprendizaje contrastivo\n",
    "train_loss = losses.CosineSimilarityLoss(model=sbert_model_fullTain)\n",
    "\n",
    "# Entrenar el modelo S-BERT utilizando el aprendizaje contrastivo\n",
    "sbert_model_fullTain.fit(train_objectives=[(train_dataloader_full, train_loss)], epochs=1, warmup_steps=100)\n",
    "print(\"Entrenamiento del S-BERT con aprendizaje contrastivo completado usando el dataset anotado automáticamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_evaluator(sbert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070636e",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "Investigar otros modelos pre-entrenados y evaluarlos con el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_preTrained = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "# You can run evaluation like so:\n",
    "dev_evaluator(sbert_preTrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d3dcc",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "Crear un conjunto de test propio, y evaluar S-BERT en dicho conjunto de datos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b3941c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom-dataset-evaluator_pearson_cosine': 1.0,\n",
       " 'custom-dataset-evaluator_spearman_cosine': 0.9999999999999999,\n",
       " 'custom-dataset-evaluator_pearson_manhattan': 1.0,\n",
       " 'custom-dataset-evaluator_spearman_manhattan': 0.9999999999999999,\n",
       " 'custom-dataset-evaluator_pearson_euclidean': 1.0,\n",
       " 'custom-dataset-evaluator_spearman_euclidean': 0.9999999999999999,\n",
       " 'custom-dataset-evaluator_pearson_dot': 1.0,\n",
       " 'custom-dataset-evaluator_spearman_dot': 0.9999999999999999,\n",
       " 'custom-dataset-evaluator_pearson_max': 1.0,\n",
       " 'custom-dataset-evaluator_spearman_max': 0.9999999999999999}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your custom lists\n",
    "sentences1 = [\"Hace mucho frio\",\"Hace mucho calor\"]\n",
    "sentences2 = [\"Hace fresco.\",\"Hace frío.\"]\n",
    "similarity_scores = [0.1,0.8]\n",
    "\n",
    "dev_evaluator_custom = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=sentences1,\n",
    "    sentences2=sentences2,\n",
    "    scores=similarity_scores,\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    name=\"custom-dataset-evaluator\"\n",
    ")\n",
    "dev_evaluator_custom(sbert_preTrained)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
