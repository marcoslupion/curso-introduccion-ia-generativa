{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando una red autoregresiva.\n",
    "\n",
    "CÃ³digo importado del libro *Generative Deep Learning* de David Foster: \n",
    "\n",
    "\n",
    "[https://learning.oreilly.com/library/view/-/9781492041931/](https://learning.oreilly.com/library/view/-/9781492041931/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, LSTM, Input, Embedding, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"archivos/CursoGenAI_UAL_03_AUX_LSTM_autoregressive.txt\"\n",
    "\n",
    "with open(filename, encoding='utf-8-sig') as f:\n",
    "    text = f.read()\n",
    "\n",
    "seq_length = 20\n",
    "start_story = '| ' * seq_length\n",
    "\n",
    "# CLEANUP\n",
    "text = text.lower()\n",
    "text = start_story + text\n",
    "text = text.replace('\\n\\n\\n\\n\\n', start_story)\n",
    "text = text.replace('\\n', ' ')\n",
    "text = re.sub('  +', '. ', text).strip()\n",
    "text = text.replace('..', '.')\n",
    "\n",
    "text = re.sub('([!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~])', r' \\1 ', text)\n",
    "text = re.sub('\\s{2,}', ' ', text)\n",
    "\n",
    "\n",
    "# TOKENIZATION\n",
    "tokenizer = Tokenizer(char_level = False, filters = '')\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "token_list = tokenizer.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 58447 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_sequences(token_list, step):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(0, len(token_list) - seq_length, step):\n",
    "        X.append(token_list[i: i + seq_length])\n",
    "        y.append(token_list[i + seq_length])\n",
    "\n",
    "    y = to_categorical(y, num_classes = total_words)\n",
    "\n",
    "    num_seq = len(X)\n",
    "    print('Number of sequences:', num_seq, \"\\n\")\n",
    "\n",
    "    return X, y, num_seq\n",
    "\n",
    "step = 1\n",
    "seq_length = 20\n",
    "X, y, num_seq = generate_sequences(token_list, step)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = 256\n",
    "embedding_size = 100\n",
    "\n",
    "text_in = Input(shape = (None,))\n",
    "x = Embedding(total_words, embedding_size)(text_in)\n",
    "x = LSTM(n_units)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "text_out = Dense(total_words, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(text_in, text_out)\n",
    "\n",
    "opti = RMSprop(lr = 0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opti)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "model.fit(X, y, epochs=epochs, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_temp(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probs = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probs)\n",
    "\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len, temp):\n",
    "    output_text = seed_text\n",
    "    seed_text = start_story + seed_text\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = token_list[-max_sequence_len:]\n",
    "        token_list = np.reshape(token_list, (1, max_sequence_len))\n",
    "\n",
    "        probs = model.predict(token_list, verbose=0)[0]\n",
    "        y_class = sample_with_temp(probs, temperature = temp)\n",
    "\n",
    "        output_word = tokenizer.index_word[y_class] if y_class > 0 else ''\n",
    "\n",
    "        if output_word == \"|\":\n",
    "            break\n",
    "\n",
    "        seed_text += output_word + ' '\n",
    "        output_text += output_word + ' '\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi, I am an engineerhunting a on . to and bears brains permanent with was concealed , a work spied i with principle donation , her the flay and convinced this he drowned . the earth and and farmer and stone . included winter '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_text = \"Hi, I am an engineer\"\n",
    "generate_text(previous_text, 40, model, seq_length, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
