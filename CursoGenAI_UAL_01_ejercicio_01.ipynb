{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21190add",
   "metadata": {},
   "source": [
    "# Curso de IA Generativa - Entrenamiento de Tokenizer Propio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d495c13",
   "metadata": {},
   "source": [
    "\n",
    "En este notebook, vamos a entrenar un tokenizer desde cero utilizando la biblioteca de Hugging Face `tokenizers`, guardarlo en un archivo `.json`, y luego evaluarlo con un archivo de prueba que contiene caracteres y estructuras Ãºnicas.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6565d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b3dab",
   "metadata": {},
   "source": [
    "## Entrenamiento de un Tokenizer Propio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374307d",
   "metadata": {},
   "source": [
    "\n",
    "Vamos a entrenar un tokenizer utilizando un pequeÃ±o corpus personalizado para adaptarlo a nuestras necesidades. Posteriormente, guardaremos este tokenizer en un archivo `.json` para su uso futuro.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d993cc6",
   "metadata": {},
   "source": [
    "Puedes usar el conjunto de datos que desees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "721a38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = [\n",
    "    \"Artificial intelligence and machine learning are evolving fields.\",\n",
    "    \"Natural language processing enables machines to understand human language.\",\n",
    "    \"Tokenizers are crucial for preparing text data for machine learning models.\"\n",
    "]\n",
    "corpus2 = [\n",
    "    \"Este es un ejemplo de entrenamiento \\n\\n\\n de tokenizer personalizado.\",\n",
    "    \"Incluimos palabras y caracteres especiales como: ðŸ˜ƒ, ðŸš€, Ã¼, Ã¸, Ï€, Î¸, Î».\",\n",
    "    \"El objetivo es comprobar cÃ³mo maneja caracteres Ãºnicos.\"\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "#tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "\n",
    "tokenizer.train_from_iterator(corpus2, trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7685c3",
   "metadata": {},
   "source": [
    "#### Guardamos el tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f1f9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"archivos/CursoGenAI_UAL_01_myTokenizer.json\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e25f05",
   "metadata": {},
   "source": [
    "## EjecuciÃ³n del Tokenizer sobre el Archivo de Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04191efe",
   "metadata": {},
   "source": [
    "\n",
    "Ahora vamos a descargar el archivo de prueba que contiene caracteres y estructuras Ãºnicas, y lo procesaremos con el tokenizer que acabamos de entrenar. \n",
    "El objetivo es examinar si el tokenizer es capaz de codificar todos los caracteres presentes en el archivo.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac6c2246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['\\n', '[UNK]', ' ', '[UNK]', 'r', 'c', '[UNK]', 'iv', 'o ', 'de ', 'p', 'r', 'u', 'e', 'b', 'a', ' c', 'o', 'n', ' caracteres ', 'y', ' ', 'es', 't', 'r', 'u', 'c', 't', 'u', 'ras ', 'Ãº', 'n', 'i', 'c', 'a', 's', '\\n\\n', 'd', 'e', '[UNK]', ' ', '[UNK]', 'u', 'n', 'ci', 'Ã³', 'n', '[UNK]', 'Ãº', 'n', 'i', 'c', 'a', '[UNK]', '[UNK]', ':', '\\n ', ' ', ' ', ' ', '[UNK]', ' ', '[UNK]', 's', 'o ', 'de ', 'e', 'mo', 'j', 'i', 's ', 'y caracteres especi', 'al', 'es ', '[UNK]', 'u', 'e ', 'n', 'o ', 'es', 't', '[UNK]', 'n', ' ', 'en', ' ', 'e', 'l', ' ', 'd', 'a', 't', 'a', 's', 'et', ' ', 'de ', '[UNK]', 'er', 'v', 'an', 't', 'es', '\\n ', ' ', ' ', ' ', 'v', 'ar', 'i', 'ab', 'l', 'e ', '[UNK]', ' ', '[UNK]', 'ðŸ˜ƒ', 'ðŸš€', '[UNK]', '[UNK]', '[UNK]', ' ', '[UNK]', ' caracteres ', 'Ãºnico', 's', ':', ' ', '[UNK]', ', ', 'Ã¸, ', 'Ã¼, ', '[UNK]', ', ', 'Ï€, ', 'Î¸, ', 'Î»', ', ', '[UNK]', '[UNK]', '[UNK]', '\\n ', ' ', ' ', ' p', 'r', 'i', 'n', 't', '[UNK]', 'v', 'ar', 'i', 'ab', 'l', 'e', '[UNK]', '\\n\\n', '[UNK]', ' ', '[UNK]', 'l', 'am', 'ad', 'a', ' ', 'a', ' ', 'l', 'a', ' ', '[UNK]', 'u', 'n', 'ci', 'Ã³', 'n', '\\n', '[UNK]', 'u', 'n', 'ci', 'Ã³', 'n', '[UNK]', 'Ãº', 'n', 'i', 'c', 'a', '[UNK]', '[UNK]']\n",
      "Token IDs: [5, 0, 6, 0, 25, 14, 0, 88, 46, 54, 24, 25, 28, 16, 13, 12, 47, 23, 22, 66, 30, 6, 84, 27, 25, 28, 14, 27, 28, 107, 34, 22, 17, 14, 12, 26, 52, 15, 16, 0, 6, 0, 28, 22, 82, 32, 22, 0, 34, 22, 17, 14, 12, 0, 0, 9, 67, 6, 6, 6, 0, 6, 0, 26, 46, 54, 16, 57, 18, 17, 41, 153, 48, 43, 0, 28, 51, 22, 46, 84, 27, 0, 22, 6, 44, 6, 16, 20, 6, 15, 12, 27, 12, 26, 85, 6, 54, 0, 45, 29, 79, 27, 84, 67, 6, 6, 6, 29, 49, 17, 76, 20, 51, 0, 6, 0, 39, 40, 0, 0, 0, 6, 0, 66, 117, 26, 9, 6, 0, 42, 116, 118, 0, 42, 121, 119, 37, 42, 0, 0, 0, 67, 6, 6, 68, 25, 17, 22, 27, 0, 29, 49, 17, 76, 20, 16, 0, 52, 0, 6, 0, 20, 78, 77, 12, 6, 12, 6, 20, 12, 6, 0, 28, 22, 82, 32, 22, 5, 0, 28, 22, 82, 32, 22, 0, 34, 22, 17, 14, 12, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Descargar el archivo de prueba\n",
    "test_file_path = \"archivos/CursoGenAI_UAL_01_testFile.py\"\n",
    "\n",
    "# Leer el contenido del archivo de prueba\n",
    "with open(test_file_path, 'r', encoding='utf-8') as file:\n",
    "    test_file_content = file.read()\n",
    "\n",
    "# Ejecutar el tokenizer sobre el archivo de prueba\n",
    "encoded_test = tokenizer.encode(test_file_content)\n",
    "print(\"Tokens:\", encoded_test.tokens)\n",
    "print(\"Token IDs:\", encoded_test.ids)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f678333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   r c iv o  de  p r u e b a  c o n  caracteres  y   es t r u c t u ras  Ãº n i c a s \n",
      "\n",
      " d e   u n ci Ã³ n Ãº n i c a : \n",
      "          s o  de  e mo j i s  y caracteres especi al es  u e  n o  es t n   en   e l   d a t a s et   de  er v an t es \n",
      "        v ar i ab l e    ðŸ˜ƒ ðŸš€    caracteres  Ãºnico s :   ,  Ã¸,  Ã¼,  ,  Ï€,  Î¸,  Î» ,  \n",
      "       p r i n t v ar i ab l e \n",
      "\n",
      "   l am ad a   a   l a   u n ci Ã³ n \n",
      " u n ci Ã³ n Ãº n i c a\n"
     ]
    }
   ],
   "source": [
    "res = tokenizer.decode(encoded_test.ids)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30962d6",
   "metadata": {},
   "source": [
    "PREGUNTA: Â¿Por quÃ© sale todo en 1 lÃ­nea al decodificar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b7e7b",
   "metadata": {},
   "source": [
    "Porque no se incorporan saltos de lÃ­nea en el entrenamiento del tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993604d0",
   "metadata": {},
   "source": [
    "## EvaluaciÃ³n de la Salida del Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc612338",
   "metadata": {},
   "source": [
    "\n",
    "Analizaremos la salida para verificar si todos los caracteres y estructuras presentes en el archivo de prueba han sido correctamente codificados con nuestros tokens personalizados.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7933864",
   "metadata": {},
   "source": [
    "# Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9a9f3c",
   "metadata": {},
   "source": [
    "### Ejercicio 1 \n",
    "- Cambia los datos de entrenamiento, incorporando un archivo que contenga datos similares al archivo \"CursoGenAI_UAL_01_testFile.py\". \n",
    "- AdemÃ¡s, estudia los diferentes parÃ¡metros que se pueden incorporar en el \"tokenizer\" y el \"trainer\" para hacer que entienda todos los caracteres, respete los espacios y no divida todo el contenido en caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "494c34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "#tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "\n",
    "test_file_path = \"archivos/mergeSort.py\"\n",
    "\n",
    "# Leer el contenido del archivo de prueba\n",
    "with open(test_file_path, 'r', encoding='utf-8') as file:\n",
    "    test_content = file.read()\n",
    "\n",
    "tokenizer.train_from_iterator(test_content, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68efa654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#   - * -   c o d i n g :   u t f - 8   - * - \n",
      " \n",
      " f r o m   t i m e   i m p o r t   t i m e \n",
      " \n",
      " d e f   m e r g e S o r t ( l i s t a ) : \n",
      "         i f   l e n ( l i s t a )   < =   1 : \n",
      "                 r e t u r n   l i s t a \n",
      " \n",
      "         m e d i o   =   l e n ( l i s t a )   /   2 \n",
      "         i z q u i e r d a   =   l i s t a [ : m e d i o ] \n",
      "         d e r e c h a   =   l i s t a [ m e d i o : ] \n",
      " \n",
      "         i z q u i e r d a   =   m e r g e S o r t ( i z q u i e r d a ) \n",
      "         d e r e c h a   =   m e r g e S o r t ( d e r e c h a ) \n",
      " \n",
      "         r e t u r n   m e r g e ( i z q u i e r d a ,   d e r e c h a ) \n",
      " \n",
      " d e f   m e r g e ( l i s t a A ,   l i s t a B ) : \n",
      "         g l o b a l   c o m p a r a c i o n e s \n",
      "         l i s t a _ n u e v a   =   [ ] \n",
      "         a   =   0 \n",
      "         b   =   0 \n",
      " \n",
      "         w h i l e   a   <   l e n ( l i s t a A )   a n d   b   <   l e n ( l i s t a B ) : \n",
      "                 c o m p a r a c i o n e s   + =   1 \n",
      " \n",
      "                 i f   l i s t a A [ a ]   <   l i s t a B [ b ] : \n",
      "                         l i s t a _ n u e v a . a p p e n d ( l i s t a A [ a ] ) \n",
      "                         a   + =   1 \n",
      "                 e l s e : \n",
      "                         l i s t a _ n u e v a . a p p e n d ( l i s t a B [ b ] ) \n",
      "                         b   + =   1 \n",
      " \n",
      "         w h i l e   a   <   l e n ( l i s t a A ) : \n",
      "                 l i s t a _ n u e v a . a p p e n d ( l i s t a A [ a ] ) \n",
      "                 a   + =   1 \n",
      " \n",
      "         w h i l e   b   <   l e n ( l i s t a B ) : \n",
      "                 l i s t a _ n u e v a . a p p e n d ( l i s t a B [ b ] ) \n",
      "                 b   + =   1 \n",
      " \n",
      "         r e t u r n   l i s t a _ n u e v a \n",
      " \n",
      " \n",
      " l i s t a   =   [ 3 6 ,   7 1 ,   1 6 ,   2 1 ,   7 3 ,   9 ,   0 ,   4 0 ,   6 6 ,   5 ] \n",
      " c o m p a r a c i o n e s   =   0 \n",
      " \n",
      " t 0   =   t i m e ( ) \n",
      " l i s t a   =   m e r g e S o r t ( l i s t a ) \n",
      " t 1   =   t i m e ( ) \n",
      " \n",
      " p r i n t   \" L i s t a   o r d e n a d a : \" \n",
      " p r i n t   l i s t a ,   \" \\ n \" \n",
      " \n",
      " p r i n t   \" T i e m p o :   { 0 : f }   s e g u n d o s \" . f o r m a t ( t 1   -   t 0 ) \n",
      " p r i n t   \" C o m p a r a c i o n e s : \" ,   c o m p a r a c i o n e s\n"
     ]
    }
   ],
   "source": [
    "encoded_test = tokenizer.encode(test_content)\n",
    "res = tokenizer.decode(encoded_test.ids)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617e125",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "Ejecuta el tokenizer anterior sobre el archivo \"quijote.txt\". Â¿QuÃ© observas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61f1032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar el archivo de prueba\n",
    "test_file_quijote = \"archivos/quijote.txt\"\n",
    "\n",
    "# Leer el contenido del archivo de prueba\n",
    "with open(test_file_quijote, 'r', encoding='utf-8') as file:\n",
    "    test_file_content_quijote = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae7874c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l   i n g e n i o s o   h i d a l g o   d o n   u i o t e   d e   l a   a n c h a \n",
      " \n",
      " \n",
      " T A S A \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "encoded_test = tokenizer.encode(test_file_content_quijote)\n",
    "res = tokenizer.decode(encoded_test.ids)\n",
    "print(res[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a01aa2",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "Ejecuta un tokenizer pre-entrenado sobre el archivo \"quijote.txt\" y \"CursoGenAI_UAL_01_testFile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9cd0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el tokenizer preentrenado GPT-2\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "283b482b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 532, 9, 12, 19617, 25, 3384, 69, 12, 23, 532, 9, 12, 198, 198, 6738, 640, 1330, 640, 198, 198, 4299, 20121, 42758, 7, 4868, 64, 2599, 198, 220, 220, 220, 611, 18896, 7, 4868, 64, 8, 19841, 352, 25, 198, 220, 220, 220, 220, 220, 220, 220, 1441, 1351, 64, 628, 220, 220, 220, 1117, 952, 796, 18896, 7, 4868, 64, 8, 1220, 362, 198, 220, 220, 220, 220, 528, 421, 959, 6814, 796, 1351, 64, 58, 25, 1150, 952, 60, 198, 220, 220, 220, 49408, 11693, 796, 1351, 64, 58, 1150, 952, 47715, 628, 220, 220, 220, 220, 528, 421, 959, 6814, 796, 20121, 42758, 7, 528, 421, 959, 6814, 8, 198, 220, 220, 220, 49408, 11693, 796, 20121, 42758, 7, 67, 567, 11693, 8, 628, 220, 220, 220, 1441, 20121, 7, 528, 421, 959, 6814, 11, 49408, 11693, 8, 198, 198, 4299, 20121, 7, 4868, 64, 32, 11, 1351, 64, 33, 2599, 198, 220, 220, 220, 3298, 4616, 49443, 274, 198, 220, 220, 220, 1351, 64, 62, 77, 518, 6862, 796, 17635, 198, 220, 220, 220, 257, 796, 657, 198, 220, 220, 220, 275, 796, 657, 628, 220, 220, 220, 981, 257, 1279, 18896, 7, 4868, 64, 32, 8, 290, 275, 1279, 18896, 7, 4868, 64, 33, 2599, 198, 220, 220, 220, 220, 220, 220, 220, 4616, 49443, 274, 15853, 352, 628, 220, 220, 220, 220, 220, 220, 220, 611, 1351, 64, 32, 58, 64, 60, 1279, 1351, 64, 33, 58, 65, 5974, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 1351, 64, 62, 77, 518, 6862, 13, 33295, 7, 4868, 64, 32, 58, 64, 12962, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 257, 15853, 352, 198, 220, 220, 220, 220, 220, 220, 220, 2073, 25, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 1351, 64, 62, 77, 518, 6862, 13, 33295, 7, 4868, 64, 33, 58, 65, 12962, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 275, 15853, 352, 628, 220, 220, 220, 981, 257, 1279, 18896, 7, 4868, 64, 32, 2599, 198, 220, 220, 220, 220, 220, 220, 220, 1351, 64, 62, 77, 518, 6862, 13, 33295, 7, 4868, 64, 32, 58, 64, 12962, 198, 220, 220, 220, 220, 220, 220, 220, 257, 15853, 352, 628, 220, 220, 220, 981, 275, 1279, 18896, 7, 4868, 64, 33, 2599, 198, 220, 220, 220, 220, 220, 220, 220, 1351, 64, 62, 77, 518, 6862, 13, 33295, 7, 4868, 64, 33, 58, 65, 12962, 198, 220, 220, 220, 220, 220, 220, 220, 275, 15853, 352, 628, 220, 220, 220, 1441, 1351, 64, 62, 77, 518, 6862, 628, 198, 4868, 64, 796, 685, 2623, 11, 9166, 11, 1467, 11, 2310, 11, 8854, 11, 860, 11, 657, 11, 2319, 11, 7930, 11, 642, 60, 198, 785, 1845, 49443, 274, 796, 657, 198, 198, 83, 15, 796, 640, 3419, 198, 4868, 64, 796, 20121, 42758, 7, 4868, 64, 8, 198, 83, 16, 796, 640, 3419, 198, 198, 4798, 366, 8053, 64, 2760, 268, 4763, 11097, 198, 4798, 1351, 64, 11, 37082, 77, 1, 198, 198, 4798, 366, 51, 26597, 7501, 25, 1391, 15, 25, 69, 92, 384, 70, 917, 418, 1911, 18982, 7, 83, 16, 532, 256, 15, 8, 198, 4798, 366, 50249, 49443, 274, 25, 1600, 4616, 49443, 274], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Tokens: ['#', 'Ä -', '*', '-', 'Ä coding', ':', 'Ä ut', 'f', '-', '8', 'Ä -', '*', '-', 'ÄŠ', 'ÄŠ', 'from', 'Ä time', 'Ä import', 'Ä time', 'ÄŠ', 'ÄŠ', 'def', 'Ä merge', 'Sort', '(', 'list', 'a', '):', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä if', 'Ä len', '(', 'list', 'a', ')', 'Ä <=', 'Ä 1', ':', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä return', 'Ä list', 'a', 'ÄŠÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä med', 'io', 'Ä =', 'Ä len', '(', 'list', 'a', ')', 'Ä /', 'Ä 2', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'iz', 'qu', 'ier', 'da', 'Ä =', 'Ä list', 'a', '[', ':', 'med', 'io', ']', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä dere', 'cha', 'Ä =', 'Ä list', 'a', '[', 'med', 'io', ':]', 'ÄŠÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'iz', 'qu', 'ier', 'da', 'Ä =', 'Ä merge', 'Sort', '(', 'iz', 'qu', 'ier', 'da', ')', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä dere', 'cha', 'Ä =', 'Ä merge', 'Sort', '(', 'd', 'ere', 'cha', ')', 'ÄŠÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä return', 'Ä merge', '(', 'iz', 'qu', 'ier', 'da', ',', 'Ä dere', 'cha', ')', 'ÄŠ', 'ÄŠ', 'def', 'Ä merge', '(', 'list', 'a', 'A', ',', 'Ä list', 'a', 'B', '):', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä global', 'Ä compar', 'acion', 'es', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä list', 'a', '_', 'n', 'ue', 'va', 'Ä =', 'Ä []', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä a', 'Ä =', 'Ä 0', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä b', 'Ä =', 'Ä 0', 'ÄŠÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä while', 'Ä a', 'Ä <', 'Ä len', '(', 'list', 'a', 'A', ')', 'Ä and', 'Ä b', 'Ä <', 'Ä len', '(', 'list', 'a', 'B', '):', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä compar', 'acion', 'es', 'Ä +=', 'Ä 1', 'ÄŠÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä if', 'Ä list', 'a', 'A', '[', 'a', ']', 'Ä <', 'Ä list', 'a', 'B', '[', 'b', ']:', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä list', 'a', '_', 'n', 'ue', 'va', '.', 'append', '(', 'list', 'a', 'A', '[', 'a', '])', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä a', 'Ä +=', 'Ä 1', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä else', ':', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä list', 'a', '_', 'n', 'ue', 'va', '.', 'append', '(', 'list', 'a', 'B', '[', 'b', '])', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä b', 'Ä +=', 'Ä 1', 'ÄŠÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä while', 'Ä a', 'Ä <', 'Ä len', '(', 'list', 'a', 'A', '):', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä list', 'a', '_', 'n', 'ue', 'va', '.', 'append', '(', 'list', 'a', 'A', '[', 'a', '])', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä a', 'Ä +=', 'Ä 1', 'ÄŠÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä while', 'Ä b', 'Ä <', 'Ä len', '(', 'list', 'a', 'B', '):', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä list', 'a', '_', 'n', 'ue', 'va', '.', 'append', '(', 'list', 'a', 'B', '[', 'b', '])', 'ÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä b', 'Ä +=', 'Ä 1', 'ÄŠÄŠ', 'Ä ', 'Ä ', 'Ä ', 'Ä return', 'Ä list', 'a', '_', 'n', 'ue', 'va', 'ÄŠÄŠ', 'ÄŠ', 'list', 'a', 'Ä =', 'Ä [', '36', ',', 'Ä 71', ',', 'Ä 16', ',', 'Ä 21', ',', 'Ä 73', ',', 'Ä 9', ',', 'Ä 0', ',', 'Ä 40', ',', 'Ä 66', ',', 'Ä 5', ']', 'ÄŠ', 'com', 'par', 'acion', 'es', 'Ä =', 'Ä 0', 'ÄŠ', 'ÄŠ', 't', '0', 'Ä =', 'Ä time', '()', 'ÄŠ', 'list', 'a', 'Ä =', 'Ä merge', 'Sort', '(', 'list', 'a', ')', 'ÄŠ', 't', '1', 'Ä =', 'Ä time', '()', 'ÄŠ', 'ÄŠ', 'print', 'Ä \"', 'List', 'a', 'Ä ord', 'en', 'ada', ':\"', 'ÄŠ', 'print', 'Ä list', 'a', ',', 'Ä \"\\\\', 'n', '\"', 'ÄŠ', 'ÄŠ', 'print', 'Ä \"', 'T', 'iem', 'po', ':', 'Ä {', '0', ':', 'f', '}', 'Ä se', 'g', 'und', 'os', '\".', 'format', '(', 't', '1', 'Ä -', 'Ä t', '0', ')', 'ÄŠ', 'print', 'Ä \"', 'Compar', 'acion', 'es', ':', '\",', 'Ä compar', 'acion', 'es']\n",
      "Token IDs: [2, 532, 9, 12, 19617, 25, 3384, 69, 12, 23, 532, 9, 12, 198, 198, 6738, 640, 1330, 640, 198, 198, 4299, 20121, 42758, 7, 4868, 64, 2599, 198, 220, 220, 220, 611, 18896, 7, 4868, 64, 8, 19841, 352, 25, 198, 220, 220, 220, 220, 220, 220, 220, 1441, 1351, 64, 628, 220, 220, 220, 1117, 952, 796, 18896, 7, 4868, 64, 8, 1220, 362, 198, 220, 220, 220, 220, 528, 421, 959, 6814, 796, 1351, 64, 58, 25, 1150, 952, 60, 198, 220, 220, 220, 49408, 11693, 796, 1351, 64, 58, 1150, 952, 47715, 628, 220, 220, 220, 220, 528, 421, 959, 6814, 796, 20121, 42758, 7, 528, 421, 959, 6814, 8, 198, 220, 220, 220, 49408, 11693, 796, 20121, 42758, 7, 67, 567, 11693, 8, 628, 220, 220, 220, 1441, 20121, 7, 528, 421, 959, 6814, 11, 49408, 11693, 8, 198, 198, 4299, 20121, 7, 4868, 64, 32, 11, 1351, 64, 33, 2599, 198, 220, 220, 220, 3298, 4616, 49443, 274, 198, 220, 220, 220, 1351, 64, 62, 77, 518, 6862, 796, 17635, 198, 220, 220, 220, 257, 796, 657, 198, 220, 220, 220, 275, 796, 657, 628, 220, 220, 220, 981, 257, 1279, 18896, 7, 4868, 64, 32, 8, 290, 275, 1279, 18896, 7, 4868, 64, 33, 2599, 198, 220, 220, 220, 220, 220, 220, 220, 4616, 49443, 274, 15853, 352, 628, 220, 220, 220, 220, 220, 220, 220, 611, 1351, 64, 32, 58, 64, 60, 1279, 1351, 64, 33, 58, 65, 5974, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 1351, 64, 62, 77, 518, 6862, 13, 33295, 7, 4868, 64, 32, 58, 64, 12962, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 257, 15853, 352, 198, 220, 220, 220, 220, 220, 220, 220, 2073, 25, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 1351, 64, 62, 77, 518, 6862, 13, 33295, 7, 4868, 64, 33, 58, 65, 12962, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 275, 15853, 352, 628, 220, 220, 220, 981, 257, 1279, 18896, 7, 4868, 64, 32, 2599, 198, 220, 220, 220, 220, 220, 220, 220, 1351, 64, 62, 77, 518, 6862, 13, 33295, 7, 4868, 64, 32, 58, 64, 12962, 198, 220, 220, 220, 220, 220, 220, 220, 257, 15853, 352, 628, 220, 220, 220, 981, 275, 1279, 18896, 7, 4868, 64, 33, 2599, 198, 220, 220, 220, 220, 220, 220, 220, 1351, 64, 62, 77, 518, 6862, 13, 33295, 7, 4868, 64, 33, 58, 65, 12962, 198, 220, 220, 220, 220, 220, 220, 220, 275, 15853, 352, 628, 220, 220, 220, 1441, 1351, 64, 62, 77, 518, 6862, 628, 198, 4868, 64, 796, 685, 2623, 11, 9166, 11, 1467, 11, 2310, 11, 8854, 11, 860, 11, 657, 11, 2319, 11, 7930, 11, 642, 60, 198, 785, 1845, 49443, 274, 796, 657, 198, 198, 83, 15, 796, 640, 3419, 198, 4868, 64, 796, 20121, 42758, 7, 4868, 64, 8, 198, 83, 16, 796, 640, 3419, 198, 198, 4798, 366, 8053, 64, 2760, 268, 4763, 11097, 198, 4798, 1351, 64, 11, 37082, 77, 1, 198, 198, 4798, 366, 51, 26597, 7501, 25, 1391, 15, 25, 69, 92, 384, 70, 917, 418, 1911, 18982, 7, 83, 16, 532, 256, 15, 8, 198, 4798, 366, 50249, 49443, 274, 25, 1600, 4616, 49443, 274]\n",
      "Secuencia reconstruida: # -*- coding: utf-8 -*-\n",
      "\n",
      "from time import time\n",
      "\n",
      "def mergeSort(lista):\n",
      "    if len(lista) <= 1:\n",
      "        return lista\n",
      "\n",
      "    medio = len(lista) / 2\n",
      "    izquierda = lista[:medio]\n",
      "    derecha = lista[medio:]\n",
      "\n",
      "    izquierda = mergeSort(izquierda)\n",
      "    derecha = mergeSort(derecha)\n",
      "\n",
      "    return merge(izquierda, derecha)\n",
      "\n",
      "def merge(listaA, listaB):\n",
      "    global comparaciones\n",
      "    lista_nueva = []\n",
      "    a = 0\n",
      "    b = 0\n",
      "\n",
      "    while a < len(listaA) and b < len(listaB):\n",
      "        comparaciones += 1\n",
      "\n",
      "        if listaA[a] < listaB[b]:\n",
      "            lista_nueva.append(listaA[a])\n",
      "            a += 1\n",
      "        else:\n",
      "            lista_nueva.append(listaB[b])\n",
      "            b += 1\n",
      "\n",
      "    while a < len(listaA):\n",
      "        lista_nueva.append(listaA[a])\n",
      "        a += 1\n",
      "\n",
      "    while b < len(listaB):\n",
      "        lista_nueva.append(listaB[b])\n",
      "        b += 1\n",
      "\n",
      "    return lista_nueva\n",
      "\n",
      "\n",
      "lista = [36, 71, 16, 21, 73, 9, 0, 40, 66, 5]\n",
      "comparaciones = 0\n",
      "\n",
      "t0 = time()\n",
      "lista = mergeSort(lista)\n",
      "t1 = time()\n",
      "\n",
      "print \"Lista ordenada:\"\n",
      "print lista, \"\\n\"\n",
      "\n",
      "print \"Tiempo: {0:f} segundos\".format(t1 - t0)\n",
      "print \"Comparaciones:\", comparaciones\n"
     ]
    }
   ],
   "source": [
    "# TokenizaciÃ³n: obtener tokens e IDs\n",
    "encoded_input = tokenizer(test_content)\n",
    "print(encoded_input)\n",
    "# Mostrar los tokens\n",
    "tokens = encoded_input.tokens()\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Mostrar los IDs\n",
    "token_ids = encoded_input['input_ids']\n",
    "print(\"Token IDs:\", token_ids)\n",
    "\n",
    "# DecodificaciÃ³n: reconstruir la secuencia original a partir de los IDs\n",
    "reconstructed_sequence = tokenizer.decode(token_ids)\n",
    "print(\"Secuencia reconstruida:\", reconstructed_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acecf496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [9527, 27016, 4267, 78, 289, 11624, 2188, 836, 2264, 2926, 1258, 390, 8591, 1869, 11693, 628, 198, 51, 1921, 32, 198, 198, 38101, 11, 16852, 7096, 78, 390, 843, 81, 4763, 11, 3671, 822, 5733, 390, 327, 6557, 76, 3301, 1619, 24448, 14364, 47692, 384, 12654, 273, 11, 390, 198, 33280, 8358, 581, 14029, 551, 424, 1482, 325, 7639, 11, 8700, 78, 331, 466, 88, 730, 8358, 11, 387, 8482, 31110, 410, 396, 78, 16964, 198, 33280, 384, 12654, 2850, 39073, 75, 555, 9195, 305, 493, 270, 377, 4533, 2574, 27016, 4267, 78, 289, 11624, 2188, 390, 8591, 1869, 11693, 11, 198, 5589, 84, 395, 78, 16964, 29825, 390, 327, 712, 39781, 10318, 9586, 430, 11, 256, 292, 8045, 269, 4763, 458, 494, 2188, 1619, 36638, 78, 198, 8019, 305, 257, 256, 411, 1667, 9586, 41200, 331, 1117, 952, 26, 1288, 269, 723, 46668, 1734, 267, 2395, 429, 64, 331, 256, 411, 458, 15702, 418, 11, 8358, 198, 282, 36638, 78, 3718, 952, 40689, 64, 1288, 36638, 78, 9195, 305, 2205, 1153, 418, 331, 645, 1151, 64, 1667, 9586, 41200, 331, 1117, 952, 11, 198, 268, 8358, 384, 387, 390, 410, 2194, 551, 20461, 417, 26, 331, 288, 959, 261, 3476, 29634, 31215, 8358, 257, 43577, 3718, 952, 198, 325, 279, 1739, 64, 410, 2194, 11, 331, 6855, 8045, 8358, 1556, 64, 256, 15462, 384, 279, 44294, 435, 26303, 952, 1619, 36638, 78, 198, 8019, 305, 11, 331, 645, 384, 279, 1739, 64, 410, 2194, 7813, 304, 8466, 13, 575, 11, 31215, 8358, 390, 18798, 1500, 68, 11, 2566, 8591, 198, 25579, 68, 551, 46929, 324, 10180, 11, 257, 1569, 600, 68, 288, 8836, 292, 1619, 18842, 390, 875, 26597, 4679, 390, 1465, 331, 198, 325, 271, 3456, 418, 331, 18912, 47756, 257, 12654, 418, 13, 198, 198, 41, 7258, 7096, 78, 390, 843, 81, 4763, 13, 198, 198, 51, 6465, 3955, 1340, 9399, 5550, 406, 1921, 13793, 49, 1404, 1921, 198, 198, 36, 4169, 9195, 305, 645, 46668, 1734, 269, 8546, 13469, 64, 8358, 645, 6053, 64, 257, 424, 2656, 26, 551, 198, 9288, 20473, 952, 390, 2376, 387, 527, 3376, 78, 11, 2566, 1556, 64, 6838, 13, 2039, 1288, 1766, 1455, 952, 390, 8591, 4627, 260, 390, 198, 35, 4267, 390, 22346, 1665, 10205, 6404, 418, 390, 8591, 26986, 32482, 390, 978, 9948, 6557, 11, 551, 2684, 3529, 390, 288, 291, 26597, 4679, 198, 2934, 1467, 3023, 257, 12654, 418, 13, 198, 198, 9527, 3476, 268, 979, 4533, 6033, 5921, 33743, 390, 8591, 18315, 2271, 13, 198, 198, 3698, 4526, 56, 198, 198, 47, 273, 18912, 14723, 16964, 636, 68, 390, 410, 418, 11, 29825, 390, 327, 712, 39781, 11, 43630, 37911, 730, 11693, 823, 32009, 18840, 198, 4188, 387, 65, 8836, 2367, 552, 84, 395, 78, 555, 9195, 305, 493, 270, 377, 4533, 2574, 27016, 4267, 78, 289, 11624, 2188, 390, 8591, 198, 44, 3702, 64, 11, 1288, 269, 723, 28686, 387, 65, 29690, 1575, 4533, 881, 78, 491, 397, 34944, 331, 6980, 285, 4669, 6184, 118, 47163, 331, 5879, 354, 28213, 11, 198, 39369, 7190, 396, 274, 331, 424, 489, 291, 459, 274, 28686, 6855, 6557, 325, 16785, 288, 283, 3476, 29634, 331, 45101, 324, 31215, 443, 198, 79, 12342, 848, 3036, 343, 11, 331, 8654, 576, 27769, 16964, 1288, 256, 26597, 7501, 8358, 14035, 2634, 325, 16785, 1113, 312, 418, 11, 267, 401, 78, 8591, 198, 28803, 395, 430, 4017, 771, 277, 20506, 26, 2376, 269, 723, 410, 396, 78, 16964, 22346, 1619, 14364, 47692, 1482, 325, 7639, 11, 16964, 18912, 14723, 198, 268, 1288, 36638, 78, 9195, 305, 384, 289, 291, 959, 261, 39990, 11844, 9324, 979, 292, 8358, 8591, 4199, 6557, 83, 3970, 6184, 118, 2528, 320, 3263, 68, 198, 1819, 43630, 730, 11693, 523, 4679, 8591, 848, 411, 72, 18840, 390, 22346, 9195, 4951, 4596, 505, 11, 37911, 936, 585, 4533, 8358, 198, 11275, 8836, 321, 418, 6855, 283, 288, 283, 1556, 64, 14364, 395, 430, 269, 2634, 67, 4712, 31215, 410, 418, 11, 551, 8591, 36638, 64, 374, 1031, 18840, 26, 331, 43630, 198, 83, 14795, 8836, 16785, 5439, 16964, 275, 2013, 13, 20139, 8591, 269, 723, 11, 16964, 28686, 289, 11736, 275, 2013, 331, 4017, 771, 11, 28686, 1801, 418, 198, 677, 29634, 331, 45101, 324, 31215, 8358, 410, 418, 11, 267, 8591, 27822, 8358, 410, 84, 47692, 279, 12342, 12575, 13235, 11, 331, 198, 3919, 267, 9535, 435, 7145, 64, 11, 24573, 6557, 271, 848, 3036, 343, 1288, 36638, 78, 220], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Tokens: ['El', 'Ä ingen', 'ios', 'o', 'Ä h', 'idal', 'go', 'Ä don', 'Ä Qu', 'ij', 'ote', 'Ä de', 'Ä la', 'Ä Man', 'cha', 'ÄŠÄŠ', 'ÄŠ', 'T', 'AS', 'A', 'ÄŠ', 'ÄŠ', 'Yo', ',', 'Ä Juan', 'Ä Gall', 'o', 'Ä de', 'Ä And', 'r', 'ada', ',', 'Ä esc', 'rib', 'ano', 'Ä de', 'Ä C', 'ÃƒÂ¡', 'm', 'ara', 'Ä del', 'Ä Rey', 'Ä nu', 'estro', 'Ä se', 'ÃƒÂ±', 'or', ',', 'Ä de', 'ÄŠ', 'los', 'Ä que', 'Ä res', 'iden', 'Ä en', 'Ä su', 'Ä Con', 'se', 'jo', ',', 'Ä certific', 'o', 'Ä y', 'Ä do', 'y', 'Ä fe', 'Ä que', ',', 'Ä ha', 'bi', 'endo', 'Ä v', 'ist', 'o', 'Ä por', 'ÄŠ', 'los', 'Ä se', 'ÃƒÂ±', 'ores', 'Ä dÃƒÂ©', 'l', 'Ä un', 'Ä lib', 'ro', 'Ä int', 'it', 'ul', 'ado', 'Ä El', 'Ä ingen', 'ios', 'o', 'Ä h', 'idal', 'go', 'Ä de', 'Ä la', 'Ä Man', 'cha', ',', 'ÄŠ', 'comp', 'u', 'est', 'o', 'Ä por', 'Ä Miguel', 'Ä de', 'Ä C', 'erv', 'antes', 'Ä Sa', 'aved', 'ra', ',', 'Ä t', 'as', 'aron', 'Ä c', 'ada', 'Ä pl', 'ie', 'go', 'Ä del', 'Ä dich', 'o', 'ÄŠ', 'lib', 'ro', 'Ä a', 'Ä t', 'res', 'Ä mar', 'aved', 'ÃƒÅƒs', 'Ä y', 'Ä med', 'io', ';', 'Ä el', 'Ä c', 'ual', 'Ä ti', 'ene', 'Ä o', 'che', 'nt', 'a', 'Ä y', 'Ä t', 'res', 'Ä pl', 'ieg', 'os', ',', 'Ä que', 'ÄŠ', 'al', 'Ä dich', 'o', 'Ä prec', 'io', 'Ä mont', 'a', 'Ä el', 'Ä dich', 'o', 'Ä lib', 'ro', 'Ä doc', 'ient', 'os', 'Ä y', 'Ä no', 'vent', 'a', 'Ä mar', 'aved', 'ÃƒÅƒs', 'Ä y', 'Ä med', 'io', ',', 'ÄŠ', 'en', 'Ä que', 'Ä se', 'Ä ha', 'Ä de', 'Ä v', 'ender', 'Ä en', 'Ä pap', 'el', ';', 'Ä y', 'Ä d', 'ier', 'on', 'Ä lic', 'encia', 'Ä para', 'Ä que', 'Ä a', 'Ä este', 'Ä prec', 'io', 'ÄŠ', 'se', 'Ä p', 'ued', 'a', 'Ä v', 'ender', ',', 'Ä y', 'Ä mand', 'aron', 'Ä que', 'Ä est', 'a', 'Ä t', 'asa', 'Ä se', 'Ä p', 'onga', 'Ä al', 'Ä princip', 'io', 'Ä del', 'Ä dich', 'o', 'ÄŠ', 'lib', 'ro', ',', 'Ä y', 'Ä no', 'Ä se', 'Ä p', 'ued', 'a', 'Ä v', 'ender', 'Ä sin', 'Ä e', 'lla', '.', 'Ä Y', ',', 'Ä para', 'Ä que', 'Ä de', 'llo', 'Ä const', 'e', ',', 'Ä di', 'Ä la', 'ÄŠ', 'present', 'e', 'Ä en', 'Ä Vall', 'ad', 'olid', ',', 'Ä a', 'Ä ve', 'int', 'e', 'Ä d', 'ÃƒÅƒ', 'as', 'Ä del', 'Ä mes', 'Ä de', 'Ä dec', 'iem', 'bre', 'Ä de', 'Ä mil', 'Ä y', 'ÄŠ', 'se', 'is', 'cient', 'os', 'Ä y', 'Ä cu', 'atro', 'Ä a', 'ÃƒÂ±', 'os', '.', 'ÄŠ', 'ÄŠ', 'J', 'uan', 'Ä Gall', 'o', 'Ä de', 'Ä And', 'r', 'ada', '.', 'ÄŠ', 'ÄŠ', 'T', 'EST', 'IM', 'ON', 'IO', 'Ä DE', 'Ä L', 'AS', 'Ä ER', 'R', 'AT', 'AS', 'ÄŠ', 'ÄŠ', 'E', 'ste', 'Ä lib', 'ro', 'Ä no', 'Ä ti', 'ene', 'Ä c', 'osa', 'Ä dign', 'a', 'Ä que', 'Ä no', 'Ä correspond', 'a', 'Ä a', 'Ä su', 'Ä original', ';', 'Ä en', 'ÄŠ', 'test', 'imon', 'io', 'Ä de', 'Ä lo', 'Ä ha', 'ber', 'Ä correct', 'o', ',', 'Ä di', 'Ä est', 'a', 'Ä fee', '.', 'Ä En', 'Ä el', 'Ä Co', 'leg', 'io', 'Ä de', 'Ä la', 'Ä Mad', 're', 'Ä de', 'ÄŠ', 'D', 'ios', 'Ä de', 'Ä los', 'Ä Te', 'ÃƒÂ³', 'log', 'os', 'Ä de', 'Ä la', 'Ä Univers', 'idad', 'Ä de', 'Ä Al', 'cal', 'ÃƒÂ¡', ',', 'Ä en', 'Ä prim', 'ero', 'Ä de', 'Ä d', 'ic', 'iem', 'bre', 'ÄŠ', 'de', 'Ä 16', '04', 'Ä a', 'ÃƒÂ±', 'os', '.', 'ÄŠ', 'ÄŠ', 'El', 'Ä lic', 'en', 'ci', 'ado', 'Ä Francisco', 'Ä Mur', 'cia', 'Ä de', 'Ä la', 'Ä Ll', 'ana', '.', 'ÄŠ', 'ÄŠ', 'EL', 'Ä RE', 'Y', 'ÄŠ', 'ÄŠ', 'P', 'or', 'Ä cu', 'anto', 'Ä por', 'Ä part', 'e', 'Ä de', 'Ä v', 'os', ',', 'Ä Miguel', 'Ä de', 'Ä C', 'erv', 'antes', ',', 'Ä nos', 'Ä fue', 'Ä fe', 'cha', 'Ä rel', 'aci', 'ÃƒÂ³n', 'ÄŠ', 'que', 'Ä ha', 'b', 'ÃƒÅƒ', 'ades', 'Ä comp', 'u', 'est', 'o', 'Ä un', 'Ä lib', 'ro', 'Ä int', 'it', 'ul', 'ado', 'Ä El', 'Ä ingen', 'ios', 'o', 'Ä h', 'idal', 'go', 'Ä de', 'Ä la', 'ÄŠ', 'M', 'anch', 'a', ',', 'Ä el', 'Ä c', 'ual', 'Ä os', 'Ä ha', 'b', 'ÃƒÅƒa', 'Ä cost', 'ado', 'Ä much', 'o', 'Ä tr', 'ab', 'ajo', 'Ä y', 'Ä era', 'Ä m', 'uy', 'Ä Ãƒ', 'Âº', 'til', 'Ä y', 'Ä prove', 'ch', 'oso', ',', 'ÄŠ', 'nos', 'Ä ped', 'ist', 'es', 'Ä y', 'Ä su', 'pl', 'ic', 'ast', 'es', 'Ä os', 'Ä mand', 'ÃƒÂ¡', 'se', 'mos', 'Ä d', 'ar', 'Ä lic', 'encia', 'Ä y', 'Ä facult', 'ad', 'Ä para', 'Ä le', 'ÄŠ', 'p', 'oder', 'Ä imp', 'rim', 'ir', ',', 'Ä y', 'Ä prev', 'ile', 'gio', 'Ä por', 'Ä el', 'Ä t', 'iem', 'po', 'Ä que', 'Ä fu', 'ÃƒÂ©', 'se', 'mos', 'Ä serv', 'id', 'os', ',', 'Ä o', 'Ä com', 'o', 'Ä la', 'ÄŠ', 'nu', 'est', 'ra', 'Ä mer', 'ced', 'Ä f', 'uese', ';', 'Ä lo', 'Ä c', 'ual', 'Ä v', 'ist', 'o', 'Ä por', 'Ä los', 'Ä del', 'Ä nu', 'estro', 'Ä Con', 'se', 'jo', ',', 'Ä por', 'Ä cu', 'anto', 'ÄŠ', 'en', 'Ä el', 'Ä dich', 'o', 'Ä lib', 'ro', 'Ä se', 'Ä h', 'ic', 'ier', 'on', 'Ä las', 'Ä dil', 'igen', 'ci', 'as', 'Ä que', 'Ä la', 'Ä prem', 'ÃƒÂ¡', 't', 'ica', 'Ä Ãƒ', 'Âº', 'lt', 'im', 'ament', 'e', 'ÄŠ', 'por', 'Ä nos', 'Ä fe', 'cha', 'Ä so', 'bre', 'Ä la', 'Ä imp', 'res', 'i', 'ÃƒÂ³n', 'Ä de', 'Ä los', 'Ä lib', 'ros', 'Ä disp', 'one', ',', 'Ä fue', 'Ä ac', 'ord', 'ado', 'Ä que', 'ÄŠ', 'deb', 'ÃƒÅƒ', 'am', 'os', 'Ä mand', 'ar', 'Ä d', 'ar', 'Ä est', 'a', 'Ä nu', 'est', 'ra', 'Ä c', 'ÃƒÂ©', 'd', 'ula', 'Ä para', 'Ä v', 'os', ',', 'Ä en', 'Ä la', 'Ä dich', 'a', 'Ä r', 'az', 'ÃƒÂ³n', ';', 'Ä y', 'Ä nos', 'ÄŠ', 't', 'uv', 'ÃƒÅƒ', 'mos', 'lo', 'Ä por', 'Ä b', 'ien', '.', 'Ä Por', 'Ä la', 'Ä c', 'ual', ',', 'Ä por', 'Ä os', 'Ä h', 'acer', 'Ä b', 'ien', 'Ä y', 'Ä mer', 'ced', ',', 'Ä os', 'Ä dam', 'os', 'ÄŠ', 'lic', 'encia', 'Ä y', 'Ä facult', 'ad', 'Ä para', 'Ä que', 'Ä v', 'os', ',', 'Ä o', 'Ä la', 'Ä persona', 'Ä que', 'Ä v', 'u', 'estro', 'Ä p', 'oder', 'Ä hub', 'iere', ',', 'Ä y', 'ÄŠ', 'no', 'Ä o', 'tra', 'Ä al', 'gun', 'a', ',', 'Ä pod', 'ÃƒÂ¡', 'is', 'Ä imp', 'rim', 'ir', 'Ä el', 'Ä dich', 'o', 'Ä ']\n",
      "Token IDs: [9527, 27016, 4267, 78, 289, 11624, 2188, 836, 2264, 2926, 1258, 390, 8591, 1869, 11693, 628, 198, 51, 1921, 32, 198, 198, 38101, 11, 16852, 7096, 78, 390, 843, 81, 4763, 11, 3671, 822, 5733, 390, 327, 6557, 76, 3301, 1619, 24448, 14364, 47692, 384, 12654, 273, 11, 390, 198, 33280, 8358, 581, 14029, 551, 424, 1482, 325, 7639, 11, 8700, 78, 331, 466, 88, 730, 8358, 11, 387, 8482, 31110, 410, 396, 78, 16964, 198, 33280, 384, 12654, 2850, 39073, 75, 555, 9195, 305, 493, 270, 377, 4533, 2574, 27016, 4267, 78, 289, 11624, 2188, 390, 8591, 1869, 11693, 11, 198, 5589, 84, 395, 78, 16964, 29825, 390, 327, 712, 39781, 10318, 9586, 430, 11, 256, 292, 8045, 269, 4763, 458, 494, 2188, 1619, 36638, 78, 198, 8019, 305, 257, 256, 411, 1667, 9586, 41200, 331, 1117, 952, 26, 1288, 269, 723, 46668, 1734, 267, 2395, 429, 64, 331, 256, 411, 458, 15702, 418, 11, 8358, 198, 282, 36638, 78, 3718, 952, 40689, 64, 1288, 36638, 78, 9195, 305, 2205, 1153, 418, 331, 645, 1151, 64, 1667, 9586, 41200, 331, 1117, 952, 11, 198, 268, 8358, 384, 387, 390, 410, 2194, 551, 20461, 417, 26, 331, 288, 959, 261, 3476, 29634, 31215, 8358, 257, 43577, 3718, 952, 198, 325, 279, 1739, 64, 410, 2194, 11, 331, 6855, 8045, 8358, 1556, 64, 256, 15462, 384, 279, 44294, 435, 26303, 952, 1619, 36638, 78, 198, 8019, 305, 11, 331, 645, 384, 279, 1739, 64, 410, 2194, 7813, 304, 8466, 13, 575, 11, 31215, 8358, 390, 18798, 1500, 68, 11, 2566, 8591, 198, 25579, 68, 551, 46929, 324, 10180, 11, 257, 1569, 600, 68, 288, 8836, 292, 1619, 18842, 390, 875, 26597, 4679, 390, 1465, 331, 198, 325, 271, 3456, 418, 331, 18912, 47756, 257, 12654, 418, 13, 198, 198, 41, 7258, 7096, 78, 390, 843, 81, 4763, 13, 198, 198, 51, 6465, 3955, 1340, 9399, 5550, 406, 1921, 13793, 49, 1404, 1921, 198, 198, 36, 4169, 9195, 305, 645, 46668, 1734, 269, 8546, 13469, 64, 8358, 645, 6053, 64, 257, 424, 2656, 26, 551, 198, 9288, 20473, 952, 390, 2376, 387, 527, 3376, 78, 11, 2566, 1556, 64, 6838, 13, 2039, 1288, 1766, 1455, 952, 390, 8591, 4627, 260, 390, 198, 35, 4267, 390, 22346, 1665, 10205, 6404, 418, 390, 8591, 26986, 32482, 390, 978, 9948, 6557, 11, 551, 2684, 3529, 390, 288, 291, 26597, 4679, 198, 2934, 1467, 3023, 257, 12654, 418, 13, 198, 198, 9527, 3476, 268, 979, 4533, 6033, 5921, 33743, 390, 8591, 18315, 2271, 13, 198, 198, 3698, 4526, 56, 198, 198, 47, 273, 18912, 14723, 16964, 636, 68, 390, 410, 418, 11, 29825, 390, 327, 712, 39781, 11, 43630, 37911, 730, 11693, 823, 32009, 18840, 198, 4188, 387, 65, 8836, 2367, 552, 84, 395, 78, 555, 9195, 305, 493, 270, 377, 4533, 2574, 27016, 4267, 78, 289, 11624, 2188, 390, 8591, 198, 44, 3702, 64, 11, 1288, 269, 723, 28686, 387, 65, 29690, 1575, 4533, 881, 78, 491, 397, 34944, 331, 6980, 285, 4669, 6184, 118, 47163, 331, 5879, 354, 28213, 11, 198, 39369, 7190, 396, 274, 331, 424, 489, 291, 459, 274, 28686, 6855, 6557, 325, 16785, 288, 283, 3476, 29634, 331, 45101, 324, 31215, 443, 198, 79, 12342, 848, 3036, 343, 11, 331, 8654, 576, 27769, 16964, 1288, 256, 26597, 7501, 8358, 14035, 2634, 325, 16785, 1113, 312, 418, 11, 267, 401, 78, 8591, 198, 28803, 395, 430, 4017, 771, 277, 20506, 26, 2376, 269, 723, 410, 396, 78, 16964, 22346, 1619, 14364, 47692, 1482, 325, 7639, 11, 16964, 18912, 14723, 198, 268, 1288, 36638, 78, 9195, 305, 384, 289, 291, 959, 261, 39990, 11844, 9324, 979, 292, 8358, 8591, 4199, 6557, 83, 3970, 6184, 118, 2528, 320, 3263, 68, 198, 1819, 43630, 730, 11693, 523, 4679, 8591, 848, 411, 72, 18840, 390, 22346, 9195, 4951, 4596, 505, 11, 37911, 936, 585, 4533, 8358, 198, 11275, 8836, 321, 418, 6855, 283, 288, 283, 1556, 64, 14364, 395, 430, 269, 2634, 67, 4712, 31215, 410, 418, 11, 551, 8591, 36638, 64, 374, 1031, 18840, 26, 331, 43630, 198, 83, 14795, 8836, 16785, 5439, 16964, 275, 2013, 13, 20139, 8591, 269, 723, 11, 16964, 28686, 289, 11736, 275, 2013, 331, 4017, 771, 11, 28686, 1801, 418, 198, 677, 29634, 331, 45101, 324, 31215, 8358, 410, 418, 11, 267, 8591, 27822, 8358, 410, 84, 47692, 279, 12342, 12575, 13235, 11, 331, 198, 3919, 267, 9535, 435, 7145, 64, 11, 24573, 6557, 271, 848, 3036, 343, 1288, 36638, 78, 220]\n",
      "Secuencia reconstruida: El ingenioso hidalgo don Quijote de la Mancha\n",
      "\n",
      "\n",
      "TASA\n",
      "\n",
      "Yo, Juan Gallo de Andrada, escribano de CÃ¡mara del Rey nuestro seÃ±or, de\n",
      "los que residen en su Consejo, certifico y doy fe que, habiendo visto por\n",
      "los seÃ±ores dÃ©l un libro intitulado El ingenioso hidalgo de la Mancha,\n",
      "compuesto por Miguel de Cervantes Saavedra, tasaron cada pliego del dicho\n",
      "libro a tres maravedÃ­s y medio; el cual tiene ochenta y tres pliegos, que\n",
      "al dicho precio monta el dicho libro docientos y noventa maravedÃ­s y medio,\n",
      "en que se ha de vender en papel; y dieron licencia para que a este precio\n",
      "se pueda vender, y mandaron que esta tasa se ponga al principio del dicho\n",
      "libro, y no se pueda vender sin ella. Y, para que dello conste, di la\n",
      "presente en Valladolid, a veinte dÃ­as del mes de deciembre de mil y\n",
      "seiscientos y cuatro aÃ±os.\n",
      "\n",
      "Juan Gallo de Andrada.\n",
      "\n",
      "TESTIMONIO DE LAS ERRATAS\n",
      "\n",
      "Este libro no tiene cosa digna que no corresponda a su original; en\n",
      "testimonio de lo haber correcto, di esta fee. En el Colegio de la Madre de\n",
      "Dios de los TeÃ³logos de la Universidad de AlcalÃ¡, en primero de diciembre\n",
      "de 1604 aÃ±os.\n",
      "\n",
      "El licenciado Francisco Murcia de la Llana.\n",
      "\n",
      "EL REY\n",
      "\n",
      "Por cuanto por parte de vos, Miguel de Cervantes, nos fue fecha relaciÃ³n\n",
      "que habÃ­ades compuesto un libro intitulado El ingenioso hidalgo de la\n",
      "Mancha, el cual os habÃ­a costado mucho trabajo y era muy Ãºtil y provechoso,\n",
      "nos pedistes y suplicastes os mandÃ¡semos dar licencia y facultad para le\n",
      "poder imprimir, y previlegio por el tiempo que fuÃ©semos servidos, o como la\n",
      "nuestra merced fuese; lo cual visto por los del nuestro Consejo, por cuanto\n",
      "en el dicho libro se hicieron las diligencias que la premÃ¡tica Ãºltimamente\n",
      "por nos fecha sobre la impresiÃ³n de los libros dispone, fue acordado que\n",
      "debÃ­amos mandar dar esta nuestra cÃ©dula para vos, en la dicha razÃ³n; y nos\n",
      "tuvÃ­moslo por bien. Por la cual, por os hacer bien y merced, os damos\n",
      "licencia y facultad para que vos, o la persona que vuestro poder hubiere, y\n",
      "no otra alguna, podÃ¡is imprimir el dicho \n"
     ]
    }
   ],
   "source": [
    "# TokenizaciÃ³n: obtener tokens e IDs\n",
    "encoded_input = tokenizer(test_file_content_quijote[0:2000])\n",
    "print(encoded_input)\n",
    "# Mostrar los tokens\n",
    "tokens = encoded_input.tokens()\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Mostrar los IDs\n",
    "token_ids = encoded_input['input_ids']\n",
    "print(\"Token IDs:\", token_ids)\n",
    "\n",
    "# DecodificaciÃ³n: reconstruir la secuencia original a partir de los IDs\n",
    "reconstructed_sequence = tokenizer.decode(token_ids)\n",
    "print(\"Secuencia reconstruida:\", reconstructed_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
